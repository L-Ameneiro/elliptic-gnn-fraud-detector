{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6ba1f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e6e02",
   "metadata": {},
   "source": [
    "Notebooks de referencia: (para borrar antes de entrega)\n",
    "\n",
    "https://www.kaggle.com/code/clemwo/bitcoin-transactions-graph-neural-networks\n",
    "\n",
    "https://www.kaggle.com/code/nidropakshin/ellptic-data-gat-tagnn\n",
    "\n",
    "https://www.kaggle.com/code/karthikapv/licit-illicit-logistic-regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb2c7c",
   "metadata": {},
   "source": [
    "### Descripci贸n del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e3d55",
   "metadata": {},
   "source": [
    "Continuaremos trabajando con Elliptic Data Set, presentado por Weber et al. en 2019 [1], el cual contiene datos anonimizados de 203,769 transacciones de Bitcoin. De la documentaci贸n del dataset sabemos que:\n",
    "\n",
    "2% de las transacciones est谩n clasificadas como il铆citas (clase 1), 21% como l铆citas (clase 2) y el 77% restante no ha sido etiquetado (clase 0). \n",
    "\n",
    "#### Features \n",
    "Cada transacci贸n corresponde a un intervalo temporal de 3 hs (time step). Los time step son 铆ndices del 1 al 49 y est谩n espaciados entre s铆 por dos semanas. Cada time step contiene un componente de transacciones conectadas entre s铆, y desconectadas del resto de los componentes. \n",
    "\n",
    "De cada transacci贸n se incluyen tambi茅n 166 variables (features) cuya descripci贸n exacta no es provista, pero se dan rasgos generales:\n",
    "\n",
    "##### Features directas de la transacci贸n (1 a 94)\n",
    "Las primeras 94 features representan informaci贸n directa de la transacci贸n. Esto incluye al time-step, la cantidad de inputs/outputs, la tarifa de transacci贸n, el volumen de output, as铆 como variables agregadas tales como la cantidad promedio de BTC recibido (gastado) por los inputs/outputs y el n煤mero promedio de transacciones entrantes asociadas con los inputs/outpus.\n",
    "\n",
    "Estas son estad铆sticas directamente relacionadas con:\n",
    "- C贸mo se construy贸 la transacci贸n\n",
    "- De qu茅 magnitud es\n",
    "- Qu茅 tan activa es la wallet involucrada\n",
    "- Cu谩nto dinero se movi贸\n",
    "\n",
    "##### Features agregadas de transacciones vecinas (95 a 166)\n",
    "Las 72 features restantes provee estad铆sticas agregadas de las transacciones vecinas (una arista de distancia). Para cada variable incluida en las features directas, se calculan agregados (m谩ximo, m铆nimo, desv铆o est谩ndar y coeficientes de correlaci贸n) de las transacciones vecinas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "86806187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los archivos\n",
    "features = pd.read_csv(\"../data/kaggle/elliptic_txs_features.csv\", header=None)\n",
    "edges = pd.read_csv(\"../data/kaggle/elliptic_txs_edgelist.csv\")\n",
    "classes = pd.read_csv(\"../data/kaggle/elliptic_txs_classes.csv\")\n",
    "\n",
    "# Renombrar columnas para claridad\n",
    "# features = features.rename(columns={0: \"txId\", 1: \"time_step\"})\n",
    "edges = edges.rename(columns={\"txId1\": \"source\", \"txId2\": \"target\"})\n",
    "classes = classes.rename(columns={\"txId\": \"txId\", \"class\": \"label\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4309caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renombrar columnas para mayor claridad\n",
    "tx_features = [\"tx_feat_\"+str(i) for i in range(2,95)]\n",
    "agg_features = [\"agg_feat_\"+str(i) for i in range(1,73)]\n",
    "features.columns = [\"txId\",\"time_step\"] + tx_features + agg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "95950b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "    Features :  203,769 (rows)   167 (cols)\n",
      "    Classes  :  203,769 (rows)     2 (cols)\n",
      "    Edgelist :  234,355 (rows)     2 (cols)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Shapes\n",
    "{4*' '}Features : {features.shape[0]:8,} (rows)  {features.shape[1]:4,} (cols)\n",
    "{4*' '}Classes  : {classes.shape[0]:8,} (rows)  {classes.shape[1]:4,} (cols)\n",
    "{4*' '}Edgelist : {edges.shape[0]:8,} (rows)  {edges.shape[1]:4,} (cols)\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa83d4",
   "metadata": {},
   "source": [
    "#### Armado de dataset para modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "acd68c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with classes\n",
    "df_features = pd.merge(features, classes, left_on='txId', right_on='txId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5bc7f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['label'] = df_features['label'].apply(lambda x: '0' if x == \"unknown\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "883891df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    157205\n",
       "1      4545\n",
       "2     42019\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequeamos que las clases nos quedaron bien armadas\n",
    "df_features.groupby('label').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993cba84",
   "metadata": {},
   "source": [
    "## Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd282713",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7dbbe7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0),\n",
       " txId           0\n",
       " time_step      0\n",
       " tx_feat_2      0\n",
       " tx_feat_3      0\n",
       " tx_feat_4      0\n",
       "               ..\n",
       " agg_feat_69    0\n",
       " agg_feat_70    0\n",
       " agg_feat_71    0\n",
       " agg_feat_72    0\n",
       " label          0\n",
       " Length: 168, dtype: int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de filas con al menos un valor nulo\n",
    "num_rows_with_nan = df_features.isnull().any(axis=1).sum()\n",
    "\n",
    "# Cantidad de datos faltantes por variable\n",
    "missing_per_col = df_features.isnull().sum()\n",
    "\n",
    "(num_rows_with_nan, missing_per_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "f0a42a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos quedamos con datos etiquetados\n",
    "data = df_features[(df_features['label']=='1') | (df_features['label']=='2')]\n",
    "\n",
    "# creamos series para modelado\n",
    "X = data[['time_step'] + tx_features+agg_features]\n",
    "y = data['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a56dfae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisi贸n entre entrenamiento y evaluaci贸n\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5a4f4b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci贸n original: label\n",
      "2    0.902392\n",
      "1    0.097608\n",
      "Name: proportion, dtype: float64\n",
      "Train: label\n",
      "2    0.901452\n",
      "1    0.098548\n",
      "Name: proportion, dtype: float64\n",
      "Test: label\n",
      "2    0.906153\n",
      "1    0.093847\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# distribuci贸n de variable target en subconjuntos de train y test\n",
    "print(\"Distribuci贸n original:\", y.value_counts(normalize=True))\n",
    "print(\"Train:\", y_train.value_counts(normalize=True))\n",
    "print(\"Test:\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620186c",
   "metadata": {},
   "source": [
    "## Modelos lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cfed0",
   "metadata": {},
   "source": [
    "### Evaluando el poder explicativo de tx_features y agg_features\n",
    "\n",
    "En este conjuntos de datos se cuenta con dos grupos de features: uno que corresponde a caracter铆sticas de cada transaccion y otro que corresponde a caracter铆sticas de su contexto inmediato. \n",
    "Para evaluar el valor explicativo de cada grupo de features, entrenamos tres tipos de modelos:\n",
    "- dos modelos parciales: s贸lo tx_features (incluye time-step) y s贸lo agg_features. \n",
    "- un modelo completo (all_features)\n",
    "\n",
    "Realizamos este an谩lisis tanto con modelos de clasificaci贸n por regresi贸n log铆stica como por descenso de gradiente.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44992e",
   "metadata": {},
   "source": [
    "#### Regresi贸n log铆stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "47978afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Resultados usando solo features de transacci贸n\n",
      "Accuracy: 0.9076592698639943\n",
      "Precision: 0.6678700361010831\n",
      "Recall: 0.13376717281272596\n",
      "F1 score: 0.22289156626506024\n",
      "Matriz de confusi贸n:\n",
      " [[  185  1198]\n",
      " [   92 12495]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Evaluar cada grupo de features\u001b[39;00m\n\u001b[32m     39\u001b[39m eval_model(X_train_tx, y_train, X_test_tx, y_test, \u001b[33m\"\u001b[39m\u001b[33msolo features de transacci贸n\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_agg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_agg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msolo features agregadas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m eval_model(X_train_all, y_train, X_test_all, y_test, \u001b[33m\"\u001b[39m\u001b[33mtodas las features\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[176]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36meval_model\u001b[39m\u001b[34m(X_train, y_train, X_test, y_test, name)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_model\u001b[39m(X_train, y_train, X_test, y_test, name):\n\u001b[32m     28\u001b[39m     clf = LogisticRegression(max_iter=\u001b[32m1000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     y_pred = clf.predict(X_test)\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Resultados usando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1384\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1382\u001b[39m     n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m fold_coefs_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1409\u001b[39m fold_coefs_, _, n_iter_ = \u001b[38;5;28mzip\u001b[39m(*fold_coefs_)\n\u001b[32m   1410\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:459\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    455\u001b[39m l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n\u001b[32m    456\u001b[39m iprint = [-\u001b[32m1\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m101\u001b[39m][\n\u001b[32m    457\u001b[39m     np.searchsorted(np.array([\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]), verbose)\n\u001b[32m    458\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m opt_res = \u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgtol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mftol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_get_additional_lbfgs_options_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miprint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m n_iter_i = _check_optimize_result(\n\u001b[32m    474\u001b[39m     solver,\n\u001b[32m    475\u001b[39m     opt_res,\n\u001b[32m    476\u001b[39m     max_iter,\n\u001b[32m    477\u001b[39m     extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[32m    478\u001b[39m )\n\u001b[32m    479\u001b[39m w0, loss = opt_res.x, opt_res.fun\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/scipy/optimize/_minimize.py:785\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    782\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    783\u001b[39m                              **options)\n\u001b[32m    784\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    788\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    789\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:469\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    461\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    472\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:403\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(x, \u001b[38;5;28mself\u001b[39m.x):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad()\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:353\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m         fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m         \u001b[38;5;28mself\u001b[39m._nfev += \u001b[32m1\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fx < \u001b[38;5;28mself\u001b[39m._lowest_f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/scipy/_lib/_util.py:583\u001b[39m, in \u001b[36m_ScalarFunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    581\u001b[39m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    582\u001b[39m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    586\u001b[39m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:80\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:74\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:332\u001b[39m, in \u001b[36mLinearModelLoss.loss_gradient\u001b[39m\u001b[34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[39m\n\u001b[32m    330\u001b[39m     grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit_intercept:\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m         grad[-\u001b[32m1\u001b[39m] = \u001b[43mgrad_pointwise\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    334\u001b[39m     grad = np.empty((n_classes, n_dof), dtype=weights.dtype, order=\u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DiploDatos/elliptic-gnn-fraud-detector/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:49\u001b[39m, in \u001b[36m_sum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     46\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     50\u001b[39m          initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prod\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     54\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "y = data['label'].astype(int)\n",
    "\n",
    "# Divisi贸n en train/test\n",
    "X_tx = data[tx_features]\n",
    "X_agg = data[agg_features]\n",
    "X_all = data[tx_features + agg_features]\n",
    "\n",
    "X_train_tx, X_test_tx, y_train, y_test = train_test_split(X_tx, y, test_size=0.3, random_state=42)\n",
    "X_train_agg, X_test_agg = train_test_split(X_agg, test_size=0.3, random_state=42)\n",
    "X_train_all, X_test_all = train_test_split(X_all, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalado (opcional pero recomendado)\n",
    "scaler_tx = StandardScaler().fit(X_train_tx)\n",
    "scaler_agg = StandardScaler().fit(X_train_agg)\n",
    "scaler_all = StandardScaler().fit(X_train_all)\n",
    "\n",
    "X_train_tx = scaler_tx.transform(X_train_tx)\n",
    "X_test_tx = scaler_tx.transform(X_test_tx)\n",
    "\n",
    "X_train_agg = scaler_agg.transform(X_train_agg)\n",
    "X_test_agg = scaler_agg.transform(X_test_agg)\n",
    "\n",
    "X_train_all = scaler_all.transform(X_train_all)\n",
    "X_test_all = scaler_all.transform(X_test_all)\n",
    "\n",
    "# Entrenar modelos\n",
    "def eval_model(X_train, y_train, X_test, y_test, name):\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Resultados usando {name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    print(\"F1 score:\", f1_score(y_test, y_pred))\n",
    "    print(\"Matriz de confusi贸n:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Evaluar cada grupo de features\n",
    "eval_model(X_train_tx, y_train, X_test_tx, y_test, \"solo features de transacci贸n\")\n",
    "eval_model(X_train_agg, y_train, X_test_agg, y_test, \"solo features agregadas\")\n",
    "eval_model(X_train_all, y_train, X_test_all, y_test, \"todas las features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010e4e23",
   "metadata": {},
   "source": [
    "### Interpretaci贸n\n",
    "Los resultados muestran que, al estimar una clasificaci贸n por regresi贸n lineal, tanto las caracter铆sticas de la transacci贸n como de su contexto inmediato tienen bajo valor predictivo, con F1 scores de 0.22 y 0.35 respectivamente. \n",
    "\n",
    "Ambos modelos parciales muestran muy baja recall, indicando que no est谩n pudiendo detectar gran parte de los casos etiquetados como fraude. \n",
    "\n",
    "El modelo con todas las features tiene un mejor desempe帽o, evidenciado en su mayor score F1, de 0.77, que se debe sobre todo a su mejor valor de recall. Esto indica que la combinaci贸n de las features de la transacci贸n y de su contexto son necesarias para predecir m谩s eficazmente los casos de fraude. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d12c037",
   "metadata": {},
   "source": [
    "#### Clasificador por gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4ffca1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Resultados usando solo features de transacci贸n (SGDClassifier)\n",
      "Accuracy: 0.9088761632068719\n",
      "Precision: 0.5986984815618221\n",
      "Recall: 0.20234604105571846\n",
      "F1 score: 0.30246575342465754\n",
      "Matriz de confusi贸n:\n",
      " [[  276  1088]\n",
      " [  185 12421]]\n",
      "\n",
      " Resultados usando solo features agregadas (SGDClassifier)\n",
      "Accuracy: 0.9234073013600572\n",
      "Precision: 0.7370967741935484\n",
      "Recall: 0.3350439882697947\n",
      "F1 score: 0.46068548387096775\n",
      "Matriz de confusi贸n:\n",
      " [[  457   907]\n",
      " [  163 12443]]\n",
      "\n",
      " Resultados usando todas las features (SGDClassifier)\n",
      "Accuracy: 0.9591982820329277\n",
      "Precision: 0.8538324420677362\n",
      "Recall: 0.7023460410557185\n",
      "F1 score: 0.7707160096540627\n",
      "Matriz de confusi贸n:\n",
      " [[  958   406]\n",
      " [  164 12442]]\n"
     ]
    }
   ],
   "source": [
    "y = data['label'].astype(int)\n",
    "\n",
    "# Divisiones con estratificaci贸n\n",
    "X_tx = data[tx_features]\n",
    "X_agg = data[agg_features]\n",
    "X_all = data[tx_features + agg_features]\n",
    "\n",
    "X_train_tx, X_test_tx, y_train, y_test = train_test_split(\n",
    "    X_tx, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_train_agg, X_test_agg = train_test_split(\n",
    "    X_agg, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_train_all, X_test_all = train_test_split(\n",
    "    X_all, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Escalado\n",
    "scaler_tx = StandardScaler().fit(X_train_tx)\n",
    "scaler_agg = StandardScaler().fit(X_train_agg)\n",
    "scaler_all = StandardScaler().fit(X_train_all)\n",
    "\n",
    "X_train_tx = scaler_tx.transform(X_train_tx)\n",
    "X_test_tx = scaler_tx.transform(X_test_tx)\n",
    "\n",
    "X_train_agg = scaler_agg.transform(X_train_agg)\n",
    "X_test_agg = scaler_agg.transform(X_test_agg)\n",
    "\n",
    "X_train_all = scaler_all.transform(X_train_all)\n",
    "X_test_all = scaler_all.transform(X_test_all)\n",
    "\n",
    "# Evaluaci贸n con SGDClassifier\n",
    "def eval_sgd(X_train, y_train, X_test, y_test, name):\n",
    "    clf = SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Resultados usando {name} (SGDClassifier)\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    print(\"F1 score:\", f1_score(y_test, y_pred))\n",
    "    print(\"Matriz de confusi贸n:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Ejecutar evaluaciones\n",
    "eval_sgd(X_train_tx, y_train, X_test_tx, y_test, \"solo features de transacci贸n\")\n",
    "eval_sgd(X_train_agg, y_train, X_test_agg, y_test, \"solo features agregadas\")\n",
    "eval_sgd(X_train_all, y_train, X_test_all, y_test, \"todas las features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7889d2",
   "metadata": {},
   "source": [
    "### Interpretaci贸n\n",
    "Nuevamente verificamos que la combinaci贸n de features de la transacci贸n y de su contexto es lo que mejor permite predecir los casos de fraude: se logra un buen nivel de recall, logrando predecir correctamente el 70% de los casos de fraude. Al mismo tiempo, se mantiene un buen nivel de precisi贸n, lo que indica baja proporci贸n de falsos positivos. \n",
    "\n",
    "Sin embargo, vemos que en este modelo ambos modelos parciales difieren notablemente en su capacidad predictiva, siendo las features del contexto las que explican m谩s varianza y tienen mayor poder predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4eaccb",
   "metadata": {},
   "source": [
    "#### Buscando el mejor modelo por descenso de gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "536440dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M茅tricas funci贸n\n",
    "def metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c2b223fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    classifier__alpha  classifier__eta0 classifier__learning_rate  \\\n",
       " 4              0.0001             0.001                   optimal   \n",
       " 13             0.0001             0.010                   optimal   \n",
       " 22             0.0001             0.100                   optimal   \n",
       " 3              0.0001             0.001                   optimal   \n",
       " 12             0.0001             0.010                   optimal   \n",
       " 21             0.0001             0.100                   optimal   \n",
       " 23             0.0001             0.100                   optimal   \n",
       " 14             0.0001             0.010                   optimal   \n",
       " 5              0.0001             0.001                   optimal   \n",
       " 31             0.0010             0.001                   optimal   \n",
       " \n",
       "    classifier__loss   mean_f1    std_f1  \n",
       " 4             hinge  0.781892  0.038922  \n",
       " 13            hinge  0.781892  0.038922  \n",
       " 22            hinge  0.781892  0.038922  \n",
       " 3          log_loss  0.763745  0.011008  \n",
       " 12         log_loss  0.763745  0.011008  \n",
       " 21         log_loss  0.763745  0.011008  \n",
       " 23   modified_huber  0.752576  0.032899  \n",
       " 14   modified_huber  0.752576  0.032899  \n",
       " 5    modified_huber  0.752576  0.032899  \n",
       " 31            hinge  0.742883  0.005001  ,\n",
       " {'classifier__alpha': 0.0001,\n",
       "  'classifier__eta0': 0.001,\n",
       "  'classifier__learning_rate': 'optimal',\n",
       "  'classifier__loss': 'hinge'},\n",
       " {'accuracy': 0.9636129348959931,\n",
       "  'precision': 0.8553615960099751,\n",
       "  'recall': 0.7547940899088337,\n",
       "  'f1': 0.801937207748831,\n",
       "  'confusion_matrix': array([[ 2401,   780],\n",
       "         [  406, 29007]])},\n",
       " {'accuracy': 0.9616320687186829,\n",
       "  'precision': 0.8404605263157895,\n",
       "  'recall': 0.749266862170088,\n",
       "  'f1': 0.7922480620155039,\n",
       "  'confusion_matrix': array([[ 1022,   342],\n",
       "         [  194, 12412]])})"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = data[tx_features + agg_features]\n",
    "\n",
    "# Split (sin escalar afuera)\n",
    "X_train_all, X_test_all, y_train, y_test = train_test_split(\n",
    "    X_all, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ========= ColumnTransformer =========\n",
    "numeric_features = X_all.columns.tolist()\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features)\n",
    "])\n",
    "\n",
    "# ========= Pipeline base =========\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SGDClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# ========= Hiperpar谩metros =========\n",
    "param_grid = {\n",
    "    'classifier__loss': ['log_loss', 'hinge', 'modified_huber'],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01],\n",
    "    'classifier__learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "    'classifier__eta0': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# ========= GridSearchCV =========\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_all, y_train)\n",
    "\n",
    "# Resultados: f1 promedio y varianza\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "\n",
    "# Resultados\n",
    "results_table = pd.DataFrame(params)\n",
    "results_table['mean_f1'] = means\n",
    "results_table['std_f1'] = stds\n",
    "\n",
    "# Mejor configuraci贸n: entrenando al mejor modelo\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Evaluaci贸n\n",
    "y_train_pred = best_estimator.predict(X_train_all)\n",
    "y_test_pred = best_estimator.predict(X_test_all)\n",
    "\n",
    "\n",
    "results_train = metrics(y_train, y_train_pred)\n",
    "results_test = metrics(y_test, y_test_pred)\n",
    "\n",
    "results_table.sort_values(by='mean_f1', ascending=False).head(10), best_params, results_train, results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ee2e7280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__alpha': 0.0001, 'classifier__eta0': 0.001, 'classifier__learning_rate': 'optimal', 'classifier__loss': 'hinge'}\n"
     ]
    }
   ],
   "source": [
    "# imprimir hiperpar谩metros del mejor modelo\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ce0871c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluaci贸n en conjunto de TEST (modelo final)\n",
      "Accuracy: 0.9616320687186829\n",
      "Precision: 0.8404605263157895\n",
      "Recall: 0.749266862170088\n",
      "F1 Score: 0.7922480620155039\n",
      "Matriz de confusi贸n:\n",
      " [[ 1022   342]\n",
      " [  194 12412]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo entrenado\n",
    "print(\"\\n Evaluaci贸n en conjunto de TEST (modelo final)\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_test_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_test_pred))\n",
    "print(\"Matriz de confusi贸n:\\n\", confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2f9d2",
   "metadata": {},
   "source": [
    "### Interpretaci贸n \n",
    "El mejor modelo encontrado es un clasificador tipo SVM lineal entrenado con SGD, con baja regularizaci贸n (alpha = 0.0001) y un learning rate adaptativo.\n",
    "\n",
    "Se obtiene un F1 score de 0.79, indicando un buen equilibrio entre recall y precisi贸n. \n",
    "\n",
    "El modelo tiene un recall de 0.75, indicando que se detectan tres cuartas partes de los casos de fraude. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edb0af",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f71ece7",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "\n",
    "1. M. Weber, G. Domeniconi, J. Chen, D. K. I. Weidele, C. Bellei, T. Robinson, C. E. Leiserson, \"Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional Networks for Financial Forensics\", KDD 19 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
